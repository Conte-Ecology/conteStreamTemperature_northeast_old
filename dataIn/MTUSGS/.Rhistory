load("C:\KPONEIL\USGS\Stream Temperature\data\temperature\fromKyle\BP_Analysis\BP_Analysis/StreamTempData_MEDMRsites.RData")
load("C:\KPONEIL\USGS\Stream Temperature\data\temperature\fromKyle\BP_Analysis\BP_Analysis/StreamTempData_MEDMRsites.RData")
load("C:/KPONEIL/USGS/Stream Temperature/data/temperature/fromKyle/BP_Analysis/BP_Analysis/StreamTempData_MEDMRsites.RData")
min(master.data$year)
max(master.data$year)
1/1/year
start.date <- 1/1/begyr
begyr <- min(master.data$year)
endyr <- max(master.data$year)
1/1/begyr
1/1/begyr
paste0(1/1/begyr)
start.date <- paste0("1/1/", begyr)
start.date
as.Date(start.date)
start.date <- paste0( begyr, "-01-01"")
start.date <- paste0( begyr, "-01-01")
as.Date(start.date)
end.date <- paste0( endyr, "-12-31")
as.Date(end.date)
date
days
days <- seq(from=as.Date(start.date),to=as.Date(end.date),by="day")
days
days <- data.frame(seq(from=as.Date(start.date),to=as.Date(end.date),by="day"))
days
head(Record)
Record <- data.frame(seq(from=as.Date(start.date),to=as.Date(end.date),by="day"))
head(Record)
names(Record) <- "Date"
Record$year <- as.numeric(strftime(Record$Date, '%Y'))
head(Record)
Record$dOY <- as.numeric(strftime(Record$date, '%j'))
class(Record$Date)
Record$dOY <- as.numeric(strftime(Record$Date, '%j'))
head(Record)
head(master.data)
Sites <- unique(master.data$site)
i = 1
temp.data <- master.data[master.data$site == Sites[i],]
A <- min(temp.data$year)
B <- max(temp.data$year)
yrs <- seq(from=A,to=B,by=1)
TempRecord <- Record[Record$year == yrs,]
TempRecord <- Record[Record$year %in% yrs,]
TempRecord
head(master.data)
test<- merge(temp.data, TempRecord, by = c('date', 'year', 'dOY'), all = T, sort = F)
head(TempRecord)
names(Record) <- "date"
Record$year <- as.numeric(strftime(Record$date, '%Y'))
Record$dOY <- as.numeric(strftime(Record$date, '%j'))
Sites <- unique(master.data$site)
#for ( i in length(Sites)){
i = 1
temp.data <- master.data[master.data$site == Sites[i],]
A <- min(temp.data$year)
B <- max(temp.data$year)
yrs <- seq(from=A,to=B,by=1)
TempRecord <- Record[Record$year %in% yrs,]
test<- merge(temp.data, TempRecord, by = c('date', 'year', 'dOY'), all = T, sort = F)
#}
head(test)
View(test)
test<- merge(temp.data, TempRecord, by = c('date', 'year', 'dOY'), all.y = T, sort = F)
View(TempRecord)
View(test)
TempRecord
head(TempRecord)
TempRecord <- Record[Record$year %in% yrs,]
View(TempRecord)
Record$year
Record$year %in% yrs
yrs
load("C:/KPONEIL/USGS/Stream Temperature/data/temperature/fromKyle/BP_Analysis/BP_Analysis/StreamTempData_MEDMRsites.RData")
begyr <- min(master.data$year)
endyr <- max(master.data$year)
#Enter Start and End dates of the period of record.
start.date <- paste0( begyr, "-01-01")
end.date <- paste0( endyr, "-12-31")
Record <- data.frame(seq(from=as.Date(start.date),to=as.Date(end.date),by="day"))
names(Record) <- "date"
Record$year <- as.numeric(strftime(Record$date, '%Y'))
Record$dOY <- as.numeric(strftime(Record$date, '%j'))
Sites <- unique(master.data$site)
#for ( i in length(Sites)){
i = 1
temp.data <- master.data[master.data$site == Sites[i],]
A <- min(temp.data$year)
B <- max(temp.data$year)
yrs <- seq(from=A,to=B,by=1)
TempRecord <- Record[Record$year %in% yrs,]
test <- merge(temp.data, TempRecord, by = c('date', 'year', 'dOY'), all.y = T, sort = F)
#}
View(TempRecord)
View(test)
test <- merge(TempRecord, temp.data, by = c('date', 'year', 'dOY'), all = T, sort = F)
test <- merge(TempRecord, temp.data, by = c('date'), all = T, sort = F)
test
View(test)
View(test)
test <- merge(TempRecord, temp.data, by = 'date', all.x = T, sort = F)
View(test)
View(temp.data)
test <- merge(TempRecord, temp.data, by = 'date', all.x = T, sort = F)
View(test)
View(TempRecord)
?merge
test <- merge(TempRecord, temp.data, by = c('year', 'dOY'), all.x = T, sort = F)
View(test)
test <- merge(TempRecord, temp.data, by = c('year', 'dOY'), all.x = T, sort = F)
test <- merge(TempRecord, temp.data, by = c("year", "dOY"), all.x = T, sort = F)
View(test)
View(TempRecord)
Record$test <- NA
TempRecord <- Record[Record$year %in% yrs,]
View(TempRecord)
test <- merge(TempRecord, temp.data, by = c("year", "dOY"), all.x = T, sort = F)
View(test)
test <- merge(TempRecord, temp.data, by = c("year", "dOY"), all.x = T, all.y = F, sort = F)
View(test)
rm(test)
test <- merge(TempRecord, temp.data, by = c("year", "dOY"), all.x = T, all.y = F, sort = F)
View(test)
min(test$date)
min(test$date.x)
test <- test[order(test$date.x),]
View(test)
tail(test)
tail(TempRecord)
test[!(test$date.x %in% TempRecord$date),]
nrow(test)
nrow(TempRecord)
sum(unique(TempRecord$date))
count(unique(TempRecord$date))
length(unique(TempRecord$date))
length(unique(test$date.x))
nrow(TempRecord)
nrow(test)
test <- test[order(test$date),]
order(test$date)
test$date
test <- merge(TempRecord, temp.data, by = 'date', all.x = T, all.y = F, sort = F)
test <- test[order(test$date),]
length(unique(TempRecord$date))
length(unique(temp.data$date))
Record <- data.frame(seq(from=as.Date(start.date),to=as.Date(end.date),by="day"))
names(Record) <- "date"
dim(Record)
begyr
endyr
Record
Sites <- unique(master.data$site)
i = 1
temp.data <- master.data[master.data$site == Sites[i],]
A <- min(temp.data$year)
B <- max(temp.data$year)
yrs <- seq(from=A,to=B,by=1)
TempRecord <- Record[Record$year %in% yrs,]
TempRecord
Record$year <- as.numeric(strftime(Record$date, '%Y'))
A <- min(temp.data$year)
B <- max(temp.data$year)
start.date <- paste0( A, "-01-01")
end.date <- paste0( B, "-12-31")
Record <- data.frame(seq(from=as.Date(start.date),to=as.Date(end.date),by="day"))
Record
test <- merge(Record, temp.data, by = 'date', all.x = T, all.y = F, sort = F)
names(Record) <- "date"
rm(test)
test <- merge(Record, temp.data, by = 'date', all.x = T, all.y = F, sort = F)
View(test)
test <- test[order(test$date),]
View(test)
?duplicate
?duplicated
what<- test[duplicated(test$date),]
what
test[(which(test$date == "2008-07-19")),]
duplicated(temp.data$date)
temp.data$site
length(duplicated(master.data$date))
rm(list=ls())
library(ggplot2)
library(GGally)
library(gridExtra)
library(reshape2)
library(mgcv)
library(nlme)
library(plyr)
library(segmented)
library(zoo)
library(ggmap)
library(pls)
library(MASS)
library(lme4)
library(DataCombine) # for the slide function
basedir <- 'C:/KPONEIL/USGS/Stream Temperature/'
#basedir <- 'D:/GitHub/'
#source('D:/GitHub/projects/temperatureProject/temperatureModelingFunctions.R')
source(paste0(basedir, 'temperatureProject/temperatureModelingFunctions.R'))
load('C:/KPONEIL/USGS/GIS/Covariate Stats/NENY_CovariateData_2014-01-23.RData')
Coords <- read.csv('C:/KPONEIL/USGS/NHDPlusV2/Modified Versions/NENY_Catch_Centroids.csv')
str(LocalStats)
head(Coords)
test <- Coords[,c('FETUREID', 'Latitude', 'Longitude')]
class(Coords)
test <- Coords[,c('FEATUREID', 'Latitude', 'Longitude')]
head(test)
test <- merge(LocalStats, Coords, by = 'FEATUREID', all.x = T, sort = F)
load('C:/KPONEIL/USGS/GIS/Covariate Stats/NENY_CovariateData_2014-01-23.RData')
Coords <- read.csv('C:/KPONEIL/USGS/NHDPlusV2/Modified Versions/NENY_Catch_Centroids.csv')
Coords <- Coords[,c('FEATUREID', 'Latitude', 'Longitude')]
test <- merge(LocalStats, Coords, by = 'FEATUREID', all.x = T, sort = F)
head(test)
test <- merge(UpstreamStats, Coords, by = 'FEATUREID', all.x = T, sort = F)
which(is.na(test$Latittude))
which(is.na(test$Latitude))
which(is.na(test$Longitude))
rm(list = ls())
load('C:/KPONEIL/USGS/GIS/Covariate Stats/NENY_CovariateData_2014-01-23.RData')
Coords <- read.csv('C:/KPONEIL/USGS/NHDPlusV2/Modified Versions/NENY_Catch_Centroids.csv')
Coords <- Coords[,c('FEATUREID', 'Latitude', 'Longitude')]
LocalStats <- merge(LocalStats, Coords, by = 'FEATUREID', all.x = T, sort = F)
UpstreamStats <- merge(UpstreamStats, Coords, by = 'FEATUREID', all.x = T, sort = F)
which(is.na(UpstreamStats$Latitude))
which(is.na(UpstreamStats$Longitude))
which(is.na(LocalStats$Longitude))
which(is.na(LocalStats$Latitude))
Sys.Date()
save(UpstreamStats, LocalStats, file = paste0('C:/KPONEIL/USGS/GIS/Covariate Stats/NENY_CovariateData_', Sys.Date(), '.RData')
)
rm(list=ls())
#rm(list=setdiff(ls(), c("Catchments","Sites")))
library(sp)
library(rgdal)
library(rgeos)
library(maptools)     # loads sp library too
library(chron)
library(ncdf)
proj4.NHD  <- "+proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs"
#Read in NHD Catchments:
Catchments <- readShapePoly ( "C:/KPONEIL/USGS/Stream Temperature/Shapefiles/NewEnglandCatchments.shp", proj4string=CRS(proj4.NHD))
#Catchments <- readShapePoly ( "C:/KPONEIL/USGS/NHDPlusV2/Modified Versions/ChamplainArea_Catchment.shp", proj4string=CRS(proj4.NHD))
#Read in delineation strings:
#load("C:/KPONEIL/USGS/GIS/Covariate Stats/DelineatedCatchments/DelineatedCatchments_NHDPlus_NENY.RData")
#DelineatedCatchmentsMaster <- NENYDelineatedCatchments
#MasterLength <- length(DelineatedCatchmentsMaster)
#Daymet variables you want:
Variables <- c("dayl", "srad", "swe", "tmax", "tmin", "prcp")
#Which year do you want data for:
year <- 2010
length(Catchment$FEATUREID)
length(Catchments$FEATUREID)
length(unique(Catchments$FEATUREID))
for ( i in 1:length(Catchments$FEATUREID)){   #Site Loop
SiteLat <- coordinates(Catchments[i,])[2]
SiteLon <- coordinates(Catchments[i,])[1]
#Index the tile by site location:
Tile <- ifelse( SiteLat > 40 & SiteLat < 42 & SiteLon > -74 & SiteLon < -72, 11754,
ifelse( SiteLat > 40 & SiteLat < 42 & SiteLon > -72 & SiteLon < -70, 11755,
ifelse( SiteLat > 40 & SiteLat < 42 & SiteLon > -70 & SiteLon < -68, 11756,
ifelse( SiteLat > 42 & SiteLat < 44 & SiteLon > -74 & SiteLon < -72, 11934,
ifelse( SiteLat > 42 & SiteLat < 44 & SiteLon > -72 & SiteLon < -70, 11935,
ifelse( SiteLat > 42 & SiteLat < 44 & SiteLon > -70 & SiteLon < -68, 11936, #**********doublecheck
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -74 & SiteLon < -72, 12114,
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -72 & SiteLon < -70, 12115,
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -70 & SiteLon < -68, 12116, #**********doublecheck
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -68 & SiteLon < -66, 12117, #**********doublecheck
ifelse( SiteLat > 46 & SiteLat < 48 & SiteLon > -72 & SiteLon < -70, 12295, #**********doublecheck
ifelse( SiteLat > 46 & SiteLat < 48 & SiteLon > -70 & SiteLon < -68, 12296, #**********doublecheck
ifelse( SiteLat > 46 & SiteLat < 48 & SiteLon > -68 & SiteLon < -66, 12297, #**********doublecheck
print("Tile Error"))))))))))))))
TileRef <- data.frame(Catchments$FEATUREID[i], Tile, SiteLon, SiteLat)
names(TileRef) <- c('FEATUREID', 'Tile', 'Lon', 'Lat' )
if ( i == 1) { Sites <- TileRef}
if ( i > 1)  { Sites <- rbind (Sites, TileRef)}
print(i)
}
dim(Sites)
head(Sites)
length(unique(Sites$FEATUREID))
Sites <- Sites[order(Sites$Tile),]
#LSites <- length(Sites$FEATUREID)
length(unique(Sites$FEATUREID))
Sites$FEATUREID
Tiles <- unique(Sites$Tile)
Tiles
CurSites <- Sites[Sites$Tile %in% Tiles[k],]
k = 1
CurSites <- Sites[Sites$Tile %in% Tiles[k],]
k = 2
CurSites <- Sites[Sites$Tile %in% Tiles[k],]
LCur <- length(CurSites$FEATUREID)
Tiles
10:9
rm(CurSites)
rm(LCur)
Tiles
start.time <- proc.time()[3]
#for (k in 1:length(Tiles)){
for (k in 10:9){
CurSites <- Sites[Sites$Tile %in% Tiles[k],]
LCur <- length(CurSites$FEATUREID)
for (j in 1:length(Variables)){
for ( i in 1:LCur){   #Site Loop
print(paste0("Processing: Site ", i," of ", LCur, "   |   Variable ", j, " of ", length(Variables), "   |   Tile: ", k, " of ", length(Tiles)))
#ifelse ( i == 1, x <- -9999, x <- Sites$Tile[i-1])
if ( i == 1) {
NCDF <- open.ncdf(paste0("C:/KPONEIL/SourceData/Projected/DAYMET/Daily/", Tiles[k], "_", year,"/", Variables[j], ".nc"))    #netcdf
#Dimension limits of each of the variables we'll use:
#----------------------------------------------------
start1 = c(1,1)
latcount <- c(NCDF$var$lat$varsize[1], NCDF$var$lat$varsize[2])
loncount <- c(NCDF$var$lon$varsize[1], NCDF$var$lon$varsize[2])
YDcount  <- NCDF$var$yearday$varsize
start2 = c(1, 1, 1)
varcount = c(NCDF$var$lat$varsize[1], NCDF$var$lat$varsize[2], NCDF$var$yearday$varsize)
#Read in variables:
#------------------
lat = get.var.ncdf ( nc=NCDF, varid="lat",                 start = start1, count = latcount )
lon = get.var.ncdf ( nc=NCDF, varid="lon",                 start = start1, count = loncount )
dOY = get.var.ncdf ( nc=NCDF, varid="yearday",             start = 1,      count = YDcount  )
var = get.var.ncdf ( nc=NCDF, varid= paste0(Variables[j]), start = start2, count = varcount )
close.ncdf(NCDF)
dOY <- dOY + 1  #Daymet doy starts at 0.
TileCoords <- cbind( as.vector(lon), as.vector(lat))
names(TileCoords) <- c('Lon', 'Lat')
TileCoordsDF <- as.data.frame(TileCoords)
}
#Find the closest daymet point to the site:
#------------------------------------------
distances <- spDistsN1(TileCoords, c(CurSites$Lon[i], CurSites$Lat[i]), longlat = TRUE)
MinDist   <- min(distances)
distpos   <- which(distances == MinDist)[1]
VarLon  <- TileCoordsDF[distpos, 1]
VarLat  <- TileCoordsDF[distpos, 2]
position <- which(lat == VarLat & lon == VarLon, arr.in = TRUE)
#Pull data from that point into dataframe:
#-----------------------------------------
temp.var <- data.frame(CurSites$FEATUREID[i], year, dOY, var[position[1], position[2], 1:365])
names(temp.var) <- c("FEATUREID", "year", "dOY", Variables[j])
#If it's the first instance, create a new storage location:
if (i == 1) {all.sites <- temp.var} else {all.sites <- rbind(all.sites, temp.var)}
}
#Join variable records together:
if (j == 1) {FullRecord <- all.sites} else {FullRecord <- merge(FullRecord, all.sites, by = c("FEATUREID", "year", "dOY"), all.x = T, sort = F)}
}
FullRecord$airTemp <- (FullRecord$tmin + FullRecord$tmax)/2
save(FullRecord, file = paste0("C:/KPONEIL/USGS/Stream Temperature/data/temperature/fromKyle/BP_Analysis/BP_Analysis/DaymetClimateData/NHD_DaymetTile_", Tiles[k],"_", year, ".RData"))
rm(all.sites, FullRecord, temp.var, CurSites, LCur)
}
end.time   <- proc.time()[3]
print(paste0((end.time-start.time)/3600, " hours"))
IndexDaymetTileByLatLon <- function(SiteLat, SiteLon){
Tile <- ifelse( SiteLat > 40 & SiteLat < 42 & SiteLon > -74 & SiteLon < -72, 11754,
ifelse( SiteLat > 40 & SiteLat < 42 & SiteLon > -72 & SiteLon < -70, 11755,
ifelse( SiteLat > 40 & SiteLat < 42 & SiteLon > -70 & SiteLon < -68, 11756,
ifelse( SiteLat > 42 & SiteLat < 44 & SiteLon > -74 & SiteLon < -72, 11934,
ifelse( SiteLat > 42 & SiteLat < 44 & SiteLon > -72 & SiteLon < -70, 11935,
ifelse( SiteLat > 42 & SiteLat < 44 & SiteLon > -70 & SiteLon < -68, 11936, #**
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -74 & SiteLon < -72, 12114,
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -72 & SiteLon < -70, 12115,
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -70 & SiteLon < -68, 12116, #**
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -68 & SiteLon < -66, 12117, #**
ifelse( SiteLat > 46 & SiteLat < 48 & SiteLon > -72 & SiteLon < -70, 12295, #**
ifelse( SiteLat > 46 & SiteLat < 48 & SiteLon > -70 & SiteLon < -68, 12296, #**
ifelse( SiteLat > 46 & SiteLat < 48 & SiteLon > -68 & SiteLon < -66, 12297, #**
print("Tile Error"))))))))))))))
return(Tile)
}
IndexDaymetTileByLatLon(45, -70)
IndexDaymetTileByLatLon(45.1, -70.1)
25*12
library(ggplot2)
library(GGally)
library(gridExtra)
library(reshape2)
library(mgcv)
library(nlme)
library(plyr)
library(segmented)
library(zoo)
library(ggmap)
library(pls)
library(MASS)
library(lme4)
library(DataCombine) # for the slide function
require(installr)
!require(installr)
if(!require(installr)) {
install.packages("installr"); require(installr)} #load /
updateR()
rm(list=ls())
library(foreign)
rasta_names <- c("prcp2010", "tmin2010", "prcp2030rcp45", "tmin2030rcp45", "prcp2080rcp45", "tmin2080rcp45","prcp2030rcp85", "tmin2030rcp85", "prcp2080rcp85", "tmin2080rcp85")
j = 1
Table <- paste0("C:/KPONEIL/USGS/GIS/Zonal Statistics/HUC_10_Albers_NENY_", rasta_names[j], ".dbf")
temp_stat <-read.dbf(Table)[,c("HUC10","MEAN")]
head(temp_stat)
temp_stat$MEAN <- temp_stat$MEAN/100
names(temp_stat)[2] <- rasta_names[j]
head(temp_stat)
rm(list=ls())
library(foreign)
rasta_names <- c("prcp2010", "tmin2010", "prcp2030rcp45", "tmin2030rcp45", "prcp2080rcp45", "tmin2080rcp45","prcp2030rcp85", "tmin2030rcp85", "prcp2080rcp85", "tmin2080rcp85")
#Loop through all of the rasters:
for (j in 1:length(rasta_names)){
Table <- paste0("C:/KPONEIL/USGS/GIS/Zonal Statistics/HUC_10_Albers_NENY_", rasta_names[j], ".dbf")
temp_stat <-read.dbf(Table)[,c("HUC10","MEAN")]
temp_stat$MEAN <- temp_stat$MEAN/100
names(temp_stat)[2] <- rasta_names[j]
if ( j == 1 ) { HUCstats <- temp_stat} else ( HUCstats <- merge(HUCstats, temp_stat, by = 'HUC10', all.x = T, sort = F))
}
head(HUCstats)
length(which(is.na(HUCstats)))
write.csv(HUCstats, file = 'C:/KPONEIL/USGS/GIS/Covariate Stats/SpatiallyAveragedStats/HUC10_CCProjections.csv')
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
updateR() # this will start the updating process of your R installation.  It will check for newer versions, and if one is available, will guide you through the decisions you'd need to make.
# installing/loading the package:
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
# using the package:
updateR() # this will start the updating process of your R installation.  It will check for newer versions, and if one is available, will guide you through the decisions you'd need to make.
sourceNames  <- c   ('CTDEP', 'MAFW', 'MAUSGS', 'NHFG', 'NHDES', 'MEDMR', 'MTUSGS')
setwd("C:/KPONEIL/GitHub/projects/temperatureProject/dataIn/", sourceNames[i])
i=1
setwd("C:/KPONEIL/GitHub/projects/temperatureProject/dataIn/", sourceNames[i])
setwd(paste0("C:/KPONEIL/GitHub/projects/temperatureProject/dataIn/", sourceNames[i]))
load(paste0('streamTempSitesObservedClimateData_', sourceNames[i]))
getwd()
load(paste0('streamTempSitesObservedClimateData_', sourceNames[i], '.RData'))
test <- masterData[,c('site', 'year', 'dOY', 'date', 'AgencyID', 'agency', 'temp', 'airTemp', 'Latitude', 'Longitude')]
head(masterData)
head9test
head(test)
paste0('streamTempData_', sourceNames[i], '.RData')
for (i in 1:length(sourceNames)){
setwd(paste0("C:/KPONEIL/GitHub/projects/temperatureProject/dataIn/", sourceNames[i]))
load(paste0('streamTempSitesObservedClimateData_', sourceNames[i], '.RData'))
masterData <- masterData[,c('site', 'year', 'dOY', 'date', 'AgencyID', 'agency', 'temp', 'airTemp', 'Latitude', 'Longitude')]
save(masterData, file = paste0('streamTempData_', sourceNames[i], '.RData'))
}
i
