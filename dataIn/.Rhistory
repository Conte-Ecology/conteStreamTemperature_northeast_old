days
days <- seq(from=as.Date(start.date),to=as.Date(end.date),by="day")
days
days <- data.frame(seq(from=as.Date(start.date),to=as.Date(end.date),by="day"))
days
head(Record)
Record <- data.frame(seq(from=as.Date(start.date),to=as.Date(end.date),by="day"))
head(Record)
names(Record) <- "Date"
Record$year <- as.numeric(strftime(Record$Date, '%Y'))
head(Record)
Record$dOY <- as.numeric(strftime(Record$date, '%j'))
class(Record$Date)
Record$dOY <- as.numeric(strftime(Record$Date, '%j'))
head(Record)
head(master.data)
Sites <- unique(master.data$site)
i = 1
temp.data <- master.data[master.data$site == Sites[i],]
A <- min(temp.data$year)
B <- max(temp.data$year)
yrs <- seq(from=A,to=B,by=1)
TempRecord <- Record[Record$year == yrs,]
TempRecord <- Record[Record$year %in% yrs,]
TempRecord
head(master.data)
test<- merge(temp.data, TempRecord, by = c('date', 'year', 'dOY'), all = T, sort = F)
head(TempRecord)
names(Record) <- "date"
Record$year <- as.numeric(strftime(Record$date, '%Y'))
Record$dOY <- as.numeric(strftime(Record$date, '%j'))
Sites <- unique(master.data$site)
#for ( i in length(Sites)){
i = 1
temp.data <- master.data[master.data$site == Sites[i],]
A <- min(temp.data$year)
B <- max(temp.data$year)
yrs <- seq(from=A,to=B,by=1)
TempRecord <- Record[Record$year %in% yrs,]
test<- merge(temp.data, TempRecord, by = c('date', 'year', 'dOY'), all = T, sort = F)
#}
head(test)
View(test)
test<- merge(temp.data, TempRecord, by = c('date', 'year', 'dOY'), all.y = T, sort = F)
View(TempRecord)
View(test)
TempRecord
head(TempRecord)
TempRecord <- Record[Record$year %in% yrs,]
View(TempRecord)
Record$year
Record$year %in% yrs
yrs
load("C:/KPONEIL/USGS/Stream Temperature/data/temperature/fromKyle/BP_Analysis/BP_Analysis/StreamTempData_MEDMRsites.RData")
begyr <- min(master.data$year)
endyr <- max(master.data$year)
#Enter Start and End dates of the period of record.
start.date <- paste0( begyr, "-01-01")
end.date <- paste0( endyr, "-12-31")
Record <- data.frame(seq(from=as.Date(start.date),to=as.Date(end.date),by="day"))
names(Record) <- "date"
Record$year <- as.numeric(strftime(Record$date, '%Y'))
Record$dOY <- as.numeric(strftime(Record$date, '%j'))
Sites <- unique(master.data$site)
#for ( i in length(Sites)){
i = 1
temp.data <- master.data[master.data$site == Sites[i],]
A <- min(temp.data$year)
B <- max(temp.data$year)
yrs <- seq(from=A,to=B,by=1)
TempRecord <- Record[Record$year %in% yrs,]
test <- merge(temp.data, TempRecord, by = c('date', 'year', 'dOY'), all.y = T, sort = F)
#}
View(TempRecord)
View(test)
test <- merge(TempRecord, temp.data, by = c('date', 'year', 'dOY'), all = T, sort = F)
test <- merge(TempRecord, temp.data, by = c('date'), all = T, sort = F)
test
View(test)
View(test)
test <- merge(TempRecord, temp.data, by = 'date', all.x = T, sort = F)
View(test)
View(temp.data)
test <- merge(TempRecord, temp.data, by = 'date', all.x = T, sort = F)
View(test)
View(TempRecord)
?merge
test <- merge(TempRecord, temp.data, by = c('year', 'dOY'), all.x = T, sort = F)
View(test)
test <- merge(TempRecord, temp.data, by = c('year', 'dOY'), all.x = T, sort = F)
test <- merge(TempRecord, temp.data, by = c("year", "dOY"), all.x = T, sort = F)
View(test)
View(TempRecord)
Record$test <- NA
TempRecord <- Record[Record$year %in% yrs,]
View(TempRecord)
test <- merge(TempRecord, temp.data, by = c("year", "dOY"), all.x = T, sort = F)
View(test)
test <- merge(TempRecord, temp.data, by = c("year", "dOY"), all.x = T, all.y = F, sort = F)
View(test)
rm(test)
test <- merge(TempRecord, temp.data, by = c("year", "dOY"), all.x = T, all.y = F, sort = F)
View(test)
min(test$date)
min(test$date.x)
test <- test[order(test$date.x),]
View(test)
tail(test)
tail(TempRecord)
test[!(test$date.x %in% TempRecord$date),]
nrow(test)
nrow(TempRecord)
sum(unique(TempRecord$date))
count(unique(TempRecord$date))
length(unique(TempRecord$date))
length(unique(test$date.x))
nrow(TempRecord)
nrow(test)
test <- test[order(test$date),]
order(test$date)
test$date
test <- merge(TempRecord, temp.data, by = 'date', all.x = T, all.y = F, sort = F)
test <- test[order(test$date),]
length(unique(TempRecord$date))
length(unique(temp.data$date))
Record <- data.frame(seq(from=as.Date(start.date),to=as.Date(end.date),by="day"))
names(Record) <- "date"
dim(Record)
begyr
endyr
Record
Sites <- unique(master.data$site)
i = 1
temp.data <- master.data[master.data$site == Sites[i],]
A <- min(temp.data$year)
B <- max(temp.data$year)
yrs <- seq(from=A,to=B,by=1)
TempRecord <- Record[Record$year %in% yrs,]
TempRecord
Record$year <- as.numeric(strftime(Record$date, '%Y'))
A <- min(temp.data$year)
B <- max(temp.data$year)
start.date <- paste0( A, "-01-01")
end.date <- paste0( B, "-12-31")
Record <- data.frame(seq(from=as.Date(start.date),to=as.Date(end.date),by="day"))
Record
test <- merge(Record, temp.data, by = 'date', all.x = T, all.y = F, sort = F)
names(Record) <- "date"
rm(test)
test <- merge(Record, temp.data, by = 'date', all.x = T, all.y = F, sort = F)
View(test)
test <- test[order(test$date),]
View(test)
?duplicate
?duplicated
what<- test[duplicated(test$date),]
what
test[(which(test$date == "2008-07-19")),]
duplicated(temp.data$date)
temp.data$site
length(duplicated(master.data$date))
rm(list=ls())
library(ggplot2)
library(GGally)
library(gridExtra)
library(reshape2)
library(mgcv)
library(nlme)
library(plyr)
library(segmented)
library(zoo)
library(ggmap)
library(pls)
library(MASS)
library(lme4)
library(DataCombine) # for the slide function
basedir <- 'C:/KPONEIL/USGS/Stream Temperature/'
#basedir <- 'D:/GitHub/'
#source('D:/GitHub/projects/temperatureProject/temperatureModelingFunctions.R')
source(paste0(basedir, 'temperatureProject/temperatureModelingFunctions.R'))
load('C:/KPONEIL/USGS/GIS/Covariate Stats/NENY_CovariateData_2014-01-23.RData')
Coords <- read.csv('C:/KPONEIL/USGS/NHDPlusV2/Modified Versions/NENY_Catch_Centroids.csv')
str(LocalStats)
head(Coords)
test <- Coords[,c('FETUREID', 'Latitude', 'Longitude')]
class(Coords)
test <- Coords[,c('FEATUREID', 'Latitude', 'Longitude')]
head(test)
test <- merge(LocalStats, Coords, by = 'FEATUREID', all.x = T, sort = F)
load('C:/KPONEIL/USGS/GIS/Covariate Stats/NENY_CovariateData_2014-01-23.RData')
Coords <- read.csv('C:/KPONEIL/USGS/NHDPlusV2/Modified Versions/NENY_Catch_Centroids.csv')
Coords <- Coords[,c('FEATUREID', 'Latitude', 'Longitude')]
test <- merge(LocalStats, Coords, by = 'FEATUREID', all.x = T, sort = F)
head(test)
test <- merge(UpstreamStats, Coords, by = 'FEATUREID', all.x = T, sort = F)
which(is.na(test$Latittude))
which(is.na(test$Latitude))
which(is.na(test$Longitude))
rm(list = ls())
load('C:/KPONEIL/USGS/GIS/Covariate Stats/NENY_CovariateData_2014-01-23.RData')
Coords <- read.csv('C:/KPONEIL/USGS/NHDPlusV2/Modified Versions/NENY_Catch_Centroids.csv')
Coords <- Coords[,c('FEATUREID', 'Latitude', 'Longitude')]
LocalStats <- merge(LocalStats, Coords, by = 'FEATUREID', all.x = T, sort = F)
UpstreamStats <- merge(UpstreamStats, Coords, by = 'FEATUREID', all.x = T, sort = F)
which(is.na(UpstreamStats$Latitude))
which(is.na(UpstreamStats$Longitude))
which(is.na(LocalStats$Longitude))
which(is.na(LocalStats$Latitude))
Sys.Date()
save(UpstreamStats, LocalStats, file = paste0('C:/KPONEIL/USGS/GIS/Covariate Stats/NENY_CovariateData_', Sys.Date(), '.RData')
)
rm(list=ls())
#rm(list=setdiff(ls(), c("Catchments","Sites")))
library(sp)
library(rgdal)
library(rgeos)
library(maptools)     # loads sp library too
library(chron)
library(ncdf)
proj4.NHD  <- "+proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs"
#Read in NHD Catchments:
Catchments <- readShapePoly ( "C:/KPONEIL/USGS/Stream Temperature/Shapefiles/NewEnglandCatchments.shp", proj4string=CRS(proj4.NHD))
#Catchments <- readShapePoly ( "C:/KPONEIL/USGS/NHDPlusV2/Modified Versions/ChamplainArea_Catchment.shp", proj4string=CRS(proj4.NHD))
#Read in delineation strings:
#load("C:/KPONEIL/USGS/GIS/Covariate Stats/DelineatedCatchments/DelineatedCatchments_NHDPlus_NENY.RData")
#DelineatedCatchmentsMaster <- NENYDelineatedCatchments
#MasterLength <- length(DelineatedCatchmentsMaster)
#Daymet variables you want:
Variables <- c("dayl", "srad", "swe", "tmax", "tmin", "prcp")
#Which year do you want data for:
year <- 2010
length(Catchment$FEATUREID)
length(Catchments$FEATUREID)
length(unique(Catchments$FEATUREID))
for ( i in 1:length(Catchments$FEATUREID)){   #Site Loop
SiteLat <- coordinates(Catchments[i,])[2]
SiteLon <- coordinates(Catchments[i,])[1]
#Index the tile by site location:
Tile <- ifelse( SiteLat > 40 & SiteLat < 42 & SiteLon > -74 & SiteLon < -72, 11754,
ifelse( SiteLat > 40 & SiteLat < 42 & SiteLon > -72 & SiteLon < -70, 11755,
ifelse( SiteLat > 40 & SiteLat < 42 & SiteLon > -70 & SiteLon < -68, 11756,
ifelse( SiteLat > 42 & SiteLat < 44 & SiteLon > -74 & SiteLon < -72, 11934,
ifelse( SiteLat > 42 & SiteLat < 44 & SiteLon > -72 & SiteLon < -70, 11935,
ifelse( SiteLat > 42 & SiteLat < 44 & SiteLon > -70 & SiteLon < -68, 11936, #**********doublecheck
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -74 & SiteLon < -72, 12114,
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -72 & SiteLon < -70, 12115,
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -70 & SiteLon < -68, 12116, #**********doublecheck
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -68 & SiteLon < -66, 12117, #**********doublecheck
ifelse( SiteLat > 46 & SiteLat < 48 & SiteLon > -72 & SiteLon < -70, 12295, #**********doublecheck
ifelse( SiteLat > 46 & SiteLat < 48 & SiteLon > -70 & SiteLon < -68, 12296, #**********doublecheck
ifelse( SiteLat > 46 & SiteLat < 48 & SiteLon > -68 & SiteLon < -66, 12297, #**********doublecheck
print("Tile Error"))))))))))))))
TileRef <- data.frame(Catchments$FEATUREID[i], Tile, SiteLon, SiteLat)
names(TileRef) <- c('FEATUREID', 'Tile', 'Lon', 'Lat' )
if ( i == 1) { Sites <- TileRef}
if ( i > 1)  { Sites <- rbind (Sites, TileRef)}
print(i)
}
dim(Sites)
head(Sites)
length(unique(Sites$FEATUREID))
Sites <- Sites[order(Sites$Tile),]
#LSites <- length(Sites$FEATUREID)
length(unique(Sites$FEATUREID))
Sites$FEATUREID
Tiles <- unique(Sites$Tile)
Tiles
CurSites <- Sites[Sites$Tile %in% Tiles[k],]
k = 1
CurSites <- Sites[Sites$Tile %in% Tiles[k],]
k = 2
CurSites <- Sites[Sites$Tile %in% Tiles[k],]
LCur <- length(CurSites$FEATUREID)
Tiles
10:9
rm(CurSites)
rm(LCur)
Tiles
start.time <- proc.time()[3]
#for (k in 1:length(Tiles)){
for (k in 10:9){
CurSites <- Sites[Sites$Tile %in% Tiles[k],]
LCur <- length(CurSites$FEATUREID)
for (j in 1:length(Variables)){
for ( i in 1:LCur){   #Site Loop
print(paste0("Processing: Site ", i," of ", LCur, "   |   Variable ", j, " of ", length(Variables), "   |   Tile: ", k, " of ", length(Tiles)))
#ifelse ( i == 1, x <- -9999, x <- Sites$Tile[i-1])
if ( i == 1) {
NCDF <- open.ncdf(paste0("C:/KPONEIL/SourceData/Projected/DAYMET/Daily/", Tiles[k], "_", year,"/", Variables[j], ".nc"))    #netcdf
#Dimension limits of each of the variables we'll use:
#----------------------------------------------------
start1 = c(1,1)
latcount <- c(NCDF$var$lat$varsize[1], NCDF$var$lat$varsize[2])
loncount <- c(NCDF$var$lon$varsize[1], NCDF$var$lon$varsize[2])
YDcount  <- NCDF$var$yearday$varsize
start2 = c(1, 1, 1)
varcount = c(NCDF$var$lat$varsize[1], NCDF$var$lat$varsize[2], NCDF$var$yearday$varsize)
#Read in variables:
#------------------
lat = get.var.ncdf ( nc=NCDF, varid="lat",                 start = start1, count = latcount )
lon = get.var.ncdf ( nc=NCDF, varid="lon",                 start = start1, count = loncount )
dOY = get.var.ncdf ( nc=NCDF, varid="yearday",             start = 1,      count = YDcount  )
var = get.var.ncdf ( nc=NCDF, varid= paste0(Variables[j]), start = start2, count = varcount )
close.ncdf(NCDF)
dOY <- dOY + 1  #Daymet doy starts at 0.
TileCoords <- cbind( as.vector(lon), as.vector(lat))
names(TileCoords) <- c('Lon', 'Lat')
TileCoordsDF <- as.data.frame(TileCoords)
}
#Find the closest daymet point to the site:
#------------------------------------------
distances <- spDistsN1(TileCoords, c(CurSites$Lon[i], CurSites$Lat[i]), longlat = TRUE)
MinDist   <- min(distances)
distpos   <- which(distances == MinDist)[1]
VarLon  <- TileCoordsDF[distpos, 1]
VarLat  <- TileCoordsDF[distpos, 2]
position <- which(lat == VarLat & lon == VarLon, arr.in = TRUE)
#Pull data from that point into dataframe:
#-----------------------------------------
temp.var <- data.frame(CurSites$FEATUREID[i], year, dOY, var[position[1], position[2], 1:365])
names(temp.var) <- c("FEATUREID", "year", "dOY", Variables[j])
#If it's the first instance, create a new storage location:
if (i == 1) {all.sites <- temp.var} else {all.sites <- rbind(all.sites, temp.var)}
}
#Join variable records together:
if (j == 1) {FullRecord <- all.sites} else {FullRecord <- merge(FullRecord, all.sites, by = c("FEATUREID", "year", "dOY"), all.x = T, sort = F)}
}
FullRecord$airTemp <- (FullRecord$tmin + FullRecord$tmax)/2
save(FullRecord, file = paste0("C:/KPONEIL/USGS/Stream Temperature/data/temperature/fromKyle/BP_Analysis/BP_Analysis/DaymetClimateData/NHD_DaymetTile_", Tiles[k],"_", year, ".RData"))
rm(all.sites, FullRecord, temp.var, CurSites, LCur)
}
end.time   <- proc.time()[3]
print(paste0((end.time-start.time)/3600, " hours"))
IndexDaymetTileByLatLon <- function(SiteLat, SiteLon){
Tile <- ifelse( SiteLat > 40 & SiteLat < 42 & SiteLon > -74 & SiteLon < -72, 11754,
ifelse( SiteLat > 40 & SiteLat < 42 & SiteLon > -72 & SiteLon < -70, 11755,
ifelse( SiteLat > 40 & SiteLat < 42 & SiteLon > -70 & SiteLon < -68, 11756,
ifelse( SiteLat > 42 & SiteLat < 44 & SiteLon > -74 & SiteLon < -72, 11934,
ifelse( SiteLat > 42 & SiteLat < 44 & SiteLon > -72 & SiteLon < -70, 11935,
ifelse( SiteLat > 42 & SiteLat < 44 & SiteLon > -70 & SiteLon < -68, 11936, #**
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -74 & SiteLon < -72, 12114,
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -72 & SiteLon < -70, 12115,
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -70 & SiteLon < -68, 12116, #**
ifelse( SiteLat > 44 & SiteLat < 46 & SiteLon > -68 & SiteLon < -66, 12117, #**
ifelse( SiteLat > 46 & SiteLat < 48 & SiteLon > -72 & SiteLon < -70, 12295, #**
ifelse( SiteLat > 46 & SiteLat < 48 & SiteLon > -70 & SiteLon < -68, 12296, #**
ifelse( SiteLat > 46 & SiteLat < 48 & SiteLon > -68 & SiteLon < -66, 12297, #**
print("Tile Error"))))))))))))))
return(Tile)
}
IndexDaymetTileByLatLon(45, -70)
IndexDaymetTileByLatLon(45.1, -70.1)
25*12
library(ggplot2)
library(GGally)
library(gridExtra)
library(reshape2)
library(mgcv)
library(nlme)
library(plyr)
library(segmented)
library(zoo)
library(ggmap)
library(pls)
library(MASS)
library(lme4)
library(DataCombine) # for the slide function
require(installr)
!require(installr)
if(!require(installr)) {
install.packages("installr"); require(installr)} #load /
updateR()
rm(list=ls())
library(foreign)
rasta_names <- c("prcp2010", "tmin2010", "prcp2030rcp45", "tmin2030rcp45", "prcp2080rcp45", "tmin2080rcp45","prcp2030rcp85", "tmin2030rcp85", "prcp2080rcp85", "tmin2080rcp85")
j = 1
Table <- paste0("C:/KPONEIL/USGS/GIS/Zonal Statistics/HUC_10_Albers_NENY_", rasta_names[j], ".dbf")
temp_stat <-read.dbf(Table)[,c("HUC10","MEAN")]
head(temp_stat)
temp_stat$MEAN <- temp_stat$MEAN/100
names(temp_stat)[2] <- rasta_names[j]
head(temp_stat)
rm(list=ls())
library(foreign)
rasta_names <- c("prcp2010", "tmin2010", "prcp2030rcp45", "tmin2030rcp45", "prcp2080rcp45", "tmin2080rcp45","prcp2030rcp85", "tmin2030rcp85", "prcp2080rcp85", "tmin2080rcp85")
#Loop through all of the rasters:
for (j in 1:length(rasta_names)){
Table <- paste0("C:/KPONEIL/USGS/GIS/Zonal Statistics/HUC_10_Albers_NENY_", rasta_names[j], ".dbf")
temp_stat <-read.dbf(Table)[,c("HUC10","MEAN")]
temp_stat$MEAN <- temp_stat$MEAN/100
names(temp_stat)[2] <- rasta_names[j]
if ( j == 1 ) { HUCstats <- temp_stat} else ( HUCstats <- merge(HUCstats, temp_stat, by = 'HUC10', all.x = T, sort = F))
}
head(HUCstats)
length(which(is.na(HUCstats)))
write.csv(HUCstats, file = 'C:/KPONEIL/USGS/GIS/Covariate Stats/SpatiallyAveragedStats/HUC10_CCProjections.csv')
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
updateR() # this will start the updating process of your R installation.  It will check for newer versions, and if one is available, will guide you through the decisions you'd need to make.
# installing/loading the package:
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
# using the package:
updateR() # this will start the updating process of your R installation.  It will check for newer versions, and if one is available, will guide you through the decisions you'd need to make.
pi
pi/2
rm(list=ls())
library(ggplot2)
library(GGally)
library(gridExtra)
library(reshape2)
library(mgcv)
library(nlme)
library(plyr)
library(segmented)
library(zoo)
library(ggmap)
library(pls)
library(MASS)
library(lme4)
library(DataCombine) # for the slide function
baseDir <- 'C:/KPONEIL/'
dataInDir <- paste0(baseDir, 'GitHub/projects/temperatureProject/dataIn/')
dataOutDir <- paste0(baseDir, 'GitHub/projects/temperatureProject/dataOut/')
graphsDir <- paste0(baseDir, 'GitHub/projects/temperatureProject/graphs/')
source(paste0(baseDir, 'GitHub/projects/temperatureProject/code/temperatureModelingFunctions.R'))
CTDEP  <- T
MAFW   <- F
MAUSGS <- F
NHFG   <- F
NHDES  <- F
MEDMR  <- F
MTUSGS <- F
sourceChoice <- list( CTDEP,   MAFW,   MAUSGS,   NHFG,   NHDES,   MEDMR,   MTUSGS )
sourceNames  <- c   ('CTDEP', 'MAFW', 'MAUSGS', 'NHFG', 'NHDES', 'MEDMR', 'MTUSGS')
dataSource <- sourceNames[sourceChoice == T]
sourceList <- paste0(paste0(dataSource, collapse = '_'), '  ', Sys.Date())
setwd(paste0(baseDir, 'GitHub/projects/temperatureProject/'))
reRunBP <- T
if( !reRunBP ) {
load(file=paste(baseDir, 'GitHub/projects/temperatureProject/e_', sourceList, '.RData',sep=''))
load(file=paste(baseDir, 'GitHub/projects/temperatureProject/et_', sourceList, '.RData',sep=''))
}
# settings variables
makeSpringFallGraphs <- T
#Creates folders for graphs if they don't exist:
#-----------------------------------------------
subGraphsDir <- paste0(graphsDir, sourceList)
if (file.exists(subGraphsDir)){
setwd(file.path(subGraphsDir))
} else {
dir.create(file.path(paste0(subGraphsDir)))
dir.create(file.path(paste0(subGraphsDir, '/summerBP')))
dir.create(file.path(paste0(subGraphsDir, '/springFallBP')))
dir.create(file.path(paste0(subGraphsDir, '/problemSites')))
}
if ( reRunBP ){
setwd(dataInDir)
for ( i in 1:length(dataSource)){
load(paste0(dataSource[i], '/streamTempData_', dataSource[i], '.RData'))  #masterData
if ( i == 1) {e <- masterData} else ( e <- rbind(e, masterData))
rm(masterData)
}
}
siteList <- unique(e$site)
#==============================================================================================
# This is the key metric for estimating the synchrony between air and water temp
e$tempIndex <- (e$temp-e$airTemp)/(e$temp + 0.00000001) # add small # to avoid Inf
#==============================================================================================
# fill in missing dOY so sequence calcs (like moving mean, slope etc)
# lag by group
e <- e[order(e$site,e$year,e$dOY),]
#For checking the order of e:
#----------------------------
e$count <- 1:length(e$year)
#Get the slope of the air/stream temperature relationship:
#---------------------------------------------------------
e$siteYear <- paste(e$site,e$year,sep='_')
e <- slide(e, Var = "temp", GroupVar = "siteYear", slideBy = +1)
e <- slide(e, Var = "airTemp", GroupVar = "siteYear", slideBy = +1)
e$rise <- e$temp1 - e$temp
e$run  <- e$airTemp1 - e$airTemp
e$slope <- e$rise / e$run
e$length <- sqrt(e$rise^2 + e$run^2)
e$angle <- atan(e$rise/e$run) * 180/pi # need to check radian units...
# for dOY changes
e$waterDelta <-    e$temp1 -    e$temp
e$airDelta   <- e$airTemp1 - e$airTemp
e <- e[order(e$count),]
#===============================================================================
#Get moving mean and SD of temp index for each site and put into the data frame:
#===============================================================================
window <- 10 # frame sizefor moving mean, which is centered by default
nSites <- length(siteList)
siteYearCombos <- unique(e[,c('site','year')])
#siteYearCombos$site  <- factor(siteYearCombos$site)
e$movingMean <- NA
e$movingSD <- NA
for (i in 1:nrow(siteYearCombos)){
print(c(i,as.character(siteYearCombos$site[i]),siteYearCombos$year[i],i/nrow(siteYearCombos)))
currSite <- which(e$site == as.character(siteYearCombos$site[i]) & e$year == siteYearCombos$year[i] )
if(length(currSite) >= window){currMean <-  rollapply(e$tempIndex[currSite], width=window, fill=NA, mean)} else(currMean <- NA)
if(length(currSite) >= window){currSD <-    rollapply(e$tempIndex[currSite], width=window, fill=NA, sd)}   else(currSD <- NA)
e$movingMean[currSite] <- currMean
e$movingSD  [currSite] <- currSD
}
e$meanSDDiff <- e$movingSD - e$movingMean
# just to make sure the merge doens't screw up order
e <- e[order(e$count),]
# look at some raw data
#ggplot( e[e$site == e$site[2] ,], aes(dOY,temp) ) + geom_point() + geom_point(aes(dOY,airTemp),color='red') + facet_grid(site~year)
#table( e$year,e$site,is.na( e$temp ) )
