```{r Load Libraries}

rm(list=ls())
library(sp)
library(rgdal)
library(rgeos)
library(maptools)
#library(chron)
```

```{r Read-in & prep data}

#NHDPlus Data:
proj4.NHD  <- "+proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs"
Catchments <- readShapePoly ( "C:/KPONEIL/USGS/NHDPlusV2/Modified Versions/NENY_NHDCatchment.shp", proj4string=CRS(proj4.NHD))

dataSource <- 'VTFWS'

#Site Location Data:
load(paste0('C:/KPONEIL/GitHub/projects/temperatureProject/dataIn/', dataSource, '/streamTempData_', dataSource, '.RData'))

sitelist<- unique(masterData$site)

for ( i in 1:length(sitelist)){
  
  Lat <- unique(masterData$Latitude[which(masterData$site == sitelist[i])])
  Lon <- unique(masterData$Longitude[which(masterData$site == sitelist[i])])
  
  temp <- data.frame(sitelist[i], Lat, Lon)
  names(temp) <- c('site', 'Latitude', 'Longitude')
  if ( i ==1) {Sites <- temp} else ( Sites <- rbind(Sites, temp))
}

#Master covariate data:
load("C:/KPONEIL/USGS/GIS/Covariate Stats/NENY_CovariateData_2014-03-12.RData")

#names(UpstreamStats)

fields <- c("FEATUREID", "ReachLengthKM", "Forest", "Herbacious", "Agriculture", "HerbaciousOrAgriculture", "Developed", 
              "DevelopedNotOpen", "Wetland", "WetlandOrWater", "Water", "UndevelopedForest", "Impervious", "AnnualTmaxC", "AnnualTminC", "WinterPrcpMM", "AnnualPrcpMM", "AtmDepositionNO3", "AtmDepositionSO4", "BasinSlopeDEG", "DrainageClass", "HydrologicGroupA", "HydrologicGroupAB", "HydrologicGroupCD", "HydrologicGroupD4", "HydrologicGroupD1", "SurficialCoarseC", "PercentSandy", "TotDASqKM", "ReachElevationM", "BasinElevationM", "SummerPrcpMM", "ReachSlopePCNT", "BasinSlopePCNT", "JanPrcpMM", "FebPrcpMM", "MarPrcpMM", "AprPrcpMM", "MayPrcpMM", "JunPrcpMM", "JulPrcpMM", "AugPrcpMM", "SepPrcpMM", "OctPrcpMM", "NovPrcpMM", "DecPrcpMM", "CONUSOpenWater", "CONUSWetland", "TNC_DamCount", "ImpoundmentsOpenSqKM", "ImpoundmentsAllSqKM", "WetlandsOpenSqKM", "WetlandsAllSqKM", "PercentImpoundedOpen", "PercentImpoundedAll", "OffChannelOpenSqKM", "OffChannelAllSqKM", "StreamOrder")


SelectUpstreamStats <- UpstreamStats[,names(UpstreamStats) %in% fields]
```

```{r Index master data}

# Set up storage for covariates:
NewCovars <- data.frame(array(NA, c(nrow(Sites),(length(fields)+ncol(Sites)))))
colnames(NewCovars) <- c("site", "Latitude", "Longitude", fields)
NewCovars[,1:3] <- Sites

start.time <- proc.time()[3]
for ( i in 1:nrow(NewCovars)){

  #Make the site a SpatialPoints object:
  point <- SpatialPoints(matrix(data=c(NewCovars$Longitude[i],NewCovars$Latitude[i]),ncol=2,byrow=T), proj4string=CRS(proj4.NHD))
  
  #Get catchment that contains the point:
  featureID <- over(point,Catchments)$FEATUREID
  
  NewCovars[i,4:ncol(NewCovars)] <- SelectUpstreamStats[SelectUpstreamStats$FEATUREID == featureID,]
  
  print(i)
}
end.time   <- proc.time()[3]
print(paste0((end.time-start.time)/3600, " hours"))

```

```{r Export Data}
covariateData <- NewCovars
save(covariateData, file = paste0('C:/KPONEIL/GitHub/projects/temperatureProject/dataIn/', dataSource, '/covariateData_', dataSource, '.RData'))

```




















#
#   IN PROGRESS: Use of parallel processing to in this code.
#

IndexSites <- function(Site){
  
  library(maptools)
  Latitude <- Locations[which(Locations$Site == Site), 'Latitude' ]
  Longitude <- Locations[which(Locations$Site == Site), 'Longitude']
  
  #Make the site a SpatialPoints object
  point <- SpatialPoints(matrix(data=c(Longitude,Latitude),ncol=2,byrow=T), proj4string=CRS(proj4.NHD))
  
  #get catchment that contains the point
  featureID <- over(point,Catchments)$FEATUREID
  
  stats <- UpstreamStats[UpstreamStats$FEATUREID == featureID,]
  
  return(c(as.character(Site), Latitude, Longitude, stats))
}


library(parallel)

values <- Sites

# Number of workers (R processes) to use:
numWorkers <- 8
# Set up the 'cluster':
cl <- makeCluster(numWorkers, type = "PSOCK")

# Load the necessary objects into the cluster:
clusterExport(cl, c("Sites", "Locations", "Catchments", "UpstreamStats", "proj4.NHD" ))
#clusterExport(cl, library(maptools))


# Execute the function:
start.time <- proc.time()[3]
Results    <- parSapply(cl, values, IndexSites)
end.time   <- proc.time()[3]
print(paste0((end.time-start.time)/3600, " hours"))

# Shut down cluster:
stopCluster(cl)

#Reformat to match "LocalStats":
rownames(Results) <- names(LocalStats)
UpstreamStats <- t(Results)
UpstreamStats <- as.data.frame(UpstreamStats)






